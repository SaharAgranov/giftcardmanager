import os
import re
import json
import time
import requests
from concurrent.futures import ThreadPoolExecutor, as_completed
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup

URL = "https://buyme.co.il/brands/13438757"

# ---------- Helper: Sanitize filename ----------
def sanitize_filename(name):
    return re.sub(r'[<>:"/\\|?*]', '-', (name or "store"))

# ---------- Helper: Download logo ----------
def download_logo(name_he, logo_url):
    if not logo_url:
        return
    os.makedirs("logos", exist_ok=True)
    safe_name = sanitize_filename(name_he)
    try:
        logo_data = requests.get(logo_url, timeout=10).content
        with open(f"logos/{safe_name}.png", "wb") as f:
            f.write(logo_data)
    except Exception as e:
        print(f"Failed to download logo for {name_he}: {e}")

# ---------- Main scraper ----------
def scrape_buyme_stores(download_logos=True, headless=False):
    # Setup Selenium
    chrome_options = Options()
    if headless:
        chrome_options.add_argument("--headless=new")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")

    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)
    driver.get(URL)

    # Give time for page to load
    time.sleep(5)

    # Incremental scrolling
    previous_count = 0
    scroll_position = 0
    scroll_step = 800

    while True:
        driver.execute_script(f"window.scrollTo(0, {scroll_position});")
        time.sleep(1)

        scroll_position += scroll_step
        current_items = len(driver.find_elements(By.CSS_SELECTOR, "div.search-bar-results__brand-item"))
        print(f"Loaded {current_items} stores...")

        if current_items == previous_count:
            # Final scroll to ensure end
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(2)
            current_items = len(driver.find_elements(By.CSS_SELECTOR, "div.search-bar-results__brand-item"))
            if current_items == previous_count:
                break
        previous_count = current_items

    print(f"Total items loaded: {previous_count}")

    # Parse final page source
    soup = BeautifulSoup(driver.page_source, "html.parser")
    driver.quit()

    # Extract stores
    stores = []
    for item in soup.select("div.search-bar-results__brand-item"):
        img_elem = item.select_one("img")
        logo_url = img_elem["src"] if img_elem else None

        # Name (alt or span)
        name_he = img_elem["alt"].strip() if img_elem and img_elem.has_attr("alt") else None
        span_elem = item.select_one("span")
        if span_elem:
            name_he = span_elem.get_text(strip=True)

        stores.append({
            "name_en": None,
            "name_he": name_he,
            "logo": logo_url,
            "store_url": None,
            "category": None
        })

    # Save JSON
    with open("buyme_stores.json", "w", encoding="utf-8") as f:
        json.dump({"brand_id": "13438757", "stores": stores}, f, ensure_ascii=False, indent=2)

    print(f"Extracted {len(stores)} stores and saved to buyme_stores.json")

    # Download logos (multi-threaded)
    if download_logos:
        print("Downloading logos...")
        with ThreadPoolExecutor(max_workers=10) as executor:
            futures = [executor.submit(download_logo, s["name_he"], s["logo"]) for s in stores]
            for _ in as_completed(futures):
                pass
        print("Logos saved in 'logos/' folder.")

# ---------- Run ----------
if __name__ == "__main__":
    scrape_buyme_stores(download_logos=True, headless=False)
